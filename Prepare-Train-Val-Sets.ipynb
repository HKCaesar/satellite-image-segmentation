{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import cv2\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "import rasterio\n",
    "import shapely.geometry\n",
    "from scipy.misc import imresize\n",
    "import pickle\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the image summary\n",
    "image_summary = gpd.read_file('vectors/shanghai_image_summary.geojson')\n",
    "\n",
    "# Load the landuse data from OSM\n",
    "osm_landuse = gpd.read_file('vectors/shanghai_landuse.geojson')\n",
    "osm_leisure = gpd.read_file('vectors/shanghai_leisure_RGB.geojson')\n",
    "\n",
    "# Convert everything to polygons\n",
    "osm_landuse.set_geometry(osm_landuse.geometry.apply(shapely.geometry.Polygon), inplace=True)\n",
    "osm_leisure.set_geometry(osm_leisure.geometry.apply(shapely.geometry.Polygon), inplace=True)\n",
    "\n",
    "# Limit to just farmland\n",
    "farmland = osm_landuse[osm_landuse.landuse == 'farmland'].unary_union\n",
    "\n",
    "files = [gpd.read_file(os.path.join('vectors/new-geojson', x)) for x in os.listdir('vectors/new-geojson')]\n",
    "manual_farmland = gpd.GeoDataFrame( pd.concat( files, ignore_index=True) )\n",
    "manual_farmland.set_geometry(manual_farmland.geometry.apply(shapely.geometry.Polygon), inplace=True)\n",
    "all_manual_farmland = manual_farmland.unary_union\n",
    "\n",
    "with open('merged_farmland.pkl', 'rb') as f:\n",
    "    merged_farmland = pickle.load(f)\n",
    "with open('all_manual_farmland.pkl', 'rb') as f:\n",
    "    all_manual_farmland = pickle.load(f)\n",
    "with open('all_farmland.pkl', 'rb') as f:\n",
    "    all_farmland = pickle.load(f)\n",
    "\n",
    "# Other categories (add in vectors)\n",
    "farmyard = osm_landuse[osm_landuse.landuse == 'farmyard'].unary_union\n",
    "industrial = osm_landuse[osm_landuse.landuse == 'industrial'].unary_union\n",
    "park = osm_leisure[osm_leisure.leisure == 'park'].unary_union\n",
    "\n",
    "vectors = [merged_farmland]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "INPUT_SIZE = 224\n",
    "\n",
    "def polycoords(poly):\n",
    "    \"\"\"Convert a polygon into the format expected by OpenCV\n",
    "    \"\"\"\n",
    "    if poly.type in ['MultiPolygon', 'GeometryCollection']:\n",
    "        return [np.array(p.exterior.coords) for p in poly if p.type == 'Polygon']\n",
    "    elif poly.type == 'Polygon':\n",
    "        return [np.array(poly.exterior.coords)]\n",
    "    else:\n",
    "        print('Encountered unrecognized geometry type {}. Ignoring.'.format(poly.type))\n",
    "        return []\n",
    "    \n",
    "def make_mask(img_shape, poly):\n",
    "    \"\"\"Make a mask from a polygon\"\"\"\n",
    "    poly_pts = polycoords(poly)\n",
    "    polys = [x.astype(int) for x in poly_pts]\n",
    "    # Create an empty mask and then fill in the polygons\n",
    "    mask = np.zeros(img_shape[:2])\n",
    "    cv2.fillPoly(mask, polys, 255)\n",
    "    return mask.astype('uint8')\n",
    "\n",
    "def scale_bands(img, lower_pct=1, upper_pct=99):\n",
    "    \"\"\"Rescale the bands of a multichannel image for display\"\"\"\n",
    "    img_scaled = np.zeros(img.shape, np.uint8)\n",
    "    for i in range(img.shape[2]):\n",
    "        band = img[:, :, i]\n",
    "        lower, upper = np.percentile(band, [lower_pct, upper_pct])\n",
    "        band = (band - lower) / (upper - lower) * 255\n",
    "        img_scaled[:, :, i] = np.clip(band, 0, 255).astype(np.uint8)\n",
    "    return img_scaled\n",
    "\n",
    "def resize(img, new_shape):\n",
    "    img_resized = np.zeros(new_shape+(img.shape[2],)).astype('float32')\n",
    "    for i in range(img.shape[2]):\n",
    "        img_resized[:, :, i] = imresize(img[:, :, i], new_shape, interp='bicubic')\n",
    "    return img_resized\n",
    "\n",
    "# Build a training set\n",
    "def make_set(image_summary, vectors, training_set_size, input_size, rows_to_use, channels=8):\n",
    "    \n",
    "    X = []\n",
    "    X_val = []\n",
    "    Y = []\n",
    "    Y_val = []\n",
    "    \n",
    "    for i, row in image_summary.loc[rows_to_use].iterrows():\n",
    "        with rasterio.open(row.image_name) as src:\n",
    "            if channels == 'bgr':\n",
    "                img = src.read([2, 3, 5]).transpose([1, 2, 0]) # BGR for VGG\n",
    "            elif channels == 'rgb':\n",
    "                img = src.read([5, 3, 2]).transpose([1, 2, 0]) \n",
    "            else:\n",
    "                img = src.read().transpose([1, 2, 0])\n",
    "            img_bounds = shapely.geometry.box(*src.bounds)\n",
    "            img_transform = list(np.array(~src.transform)[[0, 1, 3, 4, 2, 5]])\n",
    "        \n",
    "        # Ignore faulty images\n",
    "        if np.sum(img[:,:,2]==0) < 500:\n",
    "           \n",
    "            masks = []\n",
    "\n",
    "\n",
    "            for i, poly in enumerate(vectors):\n",
    "                \n",
    "                # Get the intersection between the polygon and the image bounds\n",
    "\n",
    "                if all_manual_farmland.intersection(img_bounds):\n",
    "                    mask_poly = all_manual_farmland.intersection(img_bounds)\n",
    "                else:\n",
    "                    mask_poly = all_farmland.intersection(img_bounds)\n",
    "\n",
    "                # Transform it into pixel coordinates\n",
    "                mask_poly_pxcoords = shapely.affinity.affine_transform(mask_poly, img_transform)\n",
    "\n",
    "                # Convert the polygon into a mask\n",
    "                mask = make_mask(img.shape[:2], mask_poly_pxcoords)\n",
    "                mask = imresize(mask, (INPUT_SIZE, INPUT_SIZE))\n",
    "\n",
    "                masks.append(mask[..., None])\n",
    "            masks = np.concatenate(masks, axis=2)\n",
    "            img = resize(img, (input_size, input_size))\n",
    "\n",
    "            # Add each mask to a list\n",
    "            X.append(img[None, ...])\n",
    "            Y.append(masks[None, ...])\n",
    "    \n",
    "    # Build validation set\n",
    "    for i, row in image_summary.iterrows():\n",
    "        if i not in rows_to_use:\n",
    "            with rasterio.open(row.image_name) as src:\n",
    "                if channels == 'bgr':\n",
    "                    img = src.read([2, 3, 5]).transpose([1, 2, 0]) # BGR for VGG\n",
    "                elif channels == 'rgb':\n",
    "                    img = src.read([5, 3, 2]).transpose([1, 2, 0]) \n",
    "                else:\n",
    "                    img = src.read().transpose([1, 2, 0])\n",
    "                img_bounds = shapely.geometry.box(*src.bounds)\n",
    "                img_transform = list(np.array(~src.transform)[[0, 1, 3, 4, 2, 5]])\n",
    "\n",
    "            # Ignore faulty images\n",
    "            if np.sum(img[:,:,2]==0) < 500:\n",
    "\n",
    "                masks = []\n",
    "\n",
    "                for i, poly in enumerate(vectors):\n",
    "                    \n",
    "                    # Get the intersection between the polygon and the image bounds\n",
    "                    if all_manual_farmland.intersection(img_bounds):\n",
    "                        mask_poly = all_manual_farmland.intersection(img_bounds)\n",
    "                    else:\n",
    "                        mask_poly = all_farmland.intersection(img_bounds)\n",
    "\n",
    "                    # Transform it into pixel coordinates\n",
    "                    mask_poly_pxcoords = shapely.affinity.affine_transform(mask_poly, img_transform)\n",
    "\n",
    "                    # Convert the polygon into a mask\n",
    "                    mask = make_mask(img.shape[:2], mask_poly_pxcoords)\n",
    "                    mask = imresize(mask, (INPUT_SIZE, INPUT_SIZE))\n",
    "\n",
    "                    masks.append(mask[..., None])\n",
    "                masks = np.concatenate(masks, axis=2)\n",
    "                img = resize(img, (input_size, input_size))\n",
    "\n",
    "                # Add each mask to a list\n",
    "                X_val.append(img[None, ...])\n",
    "                Y_val.append(masks[None, ...])\n",
    "            \n",
    "    # Concatenate the results\n",
    "    X = np.concatenate(X, axis=0)\n",
    "    Y = np.concatenate(Y, axis=0)\n",
    "\n",
    "    X_val = np.concatenate(X_val, axis=0)\n",
    "    Y_val = np.concatenate(Y_val, axis=0)\n",
    "    \n",
    "    # Normalize the values\n",
    "    X = X.astype('float32')\n",
    "    X = (X / X.max() - 0.5) * 2 # put X in range [-1, 1]\n",
    "\n",
    "    Y = Y.astype('float32') / 255 # put Y in range [0, 1]\n",
    "        \n",
    "    X_val = X_val.astype('float32')\n",
    "    X_val = (X_val / X_val.max() - 0.5) * 2 # put X in range [-1, 1]\n",
    "    \n",
    "    Y_val = Y_val.astype('float32') / 255 # put Y in range [0, 1]\n",
    "    \n",
    "    return X, Y, X_val, Y_val    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rows_to_use = np.random.choice(image_summary.index, 4000, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_vgg, Y_train_vgg, X_val_vgg, Y_val_vgg = make_set(image_summary, vectors, 4000, INPUT_SIZE, rows_to_use, channels='bgr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train_unet, Y_train_unet, X_val_unet, Y_val_unet = make_set(image_summary, vectors, 4000, INPUT_SIZE, rows_to_use, channels=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_resnet, Y_train_resnet, X_val_resnet, Y_val_resnet = make_set(image_summary, vectors, 4000, INPUT_SIZE, rows_to_use, channels='rgb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_unet_256, Y_train_unet_256, X_val_unet_256, Y_val_unet_256 = make_set(image_summary, vectors, 4000, INPUT_SIZE, rows_to_use, channels=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3622, 224, 224, 3)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_vgg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(517, 224, 224, 3)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val_vgg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3622, 224, 224, 8)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_unet.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(517, 224, 224, 8)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val_unet.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3622, 224, 224, 1)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train_vgg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3622, 224, 224, 1)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train_unet.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(517, 224, 224, 1)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_val_vgg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(517, 224, 224, 1)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_val_unet.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('mn_xtrain_224_bgr_man.pkl', 'wb') as f:\n",
    "    pickle.dump(X_train_vgg, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('mn_xtrain_224_8channel_man.pkl', 'wb') as f:\n",
    "    pickle.dump(X_train_unet, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('mn_ytrain_224_man.pkl', 'wb') as f:\n",
    "    pickle.dump(Y_train_unet, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('mn_xval_224_bgr_man.pkl', 'wb') as f:\n",
    "    pickle.dump(X_val_vgg, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('mn_xval_224_8channel_man.pkl', 'wb') as f:\n",
    "    pickle.dump(X_val_unet, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('mn_yval_224_man.pkl', 'wb') as f:\n",
    "    pickle.dump(Y_val_unet, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('mn_xtrain_256_rgb_man.pkl', 'wb') as f:\n",
    "    pickle.dump(X_train_resnet, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('mn_ytrain_256_man.pkl', 'wb') as f:\n",
    "    pickle.dump(Y_train_resnet, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('mn_xval_256_rgb_man.pkl', 'wb') as f:\n",
    "    pickle.dump(X_val_resnet, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('mn_yval_256_man.pkl', 'wb') as f:\n",
    "    pickle.dump(Y_val_resnet, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('mn_xtrain_256_8channel_man.pkl', 'wb') as f:\n",
    "    pickle.dump(X_train_unet_256, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('mn_xval_256_8channel_man.pkl', 'wb') as f:\n",
    "    pickle.dump(X_val_unet_256, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
